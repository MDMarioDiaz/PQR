# Fundamentos de Privacidad

En este repositorio compilamos una serie de Jupyter Notebooks dedicados a explicar fundamentos básicos de privacidad en estadística y aprandizaje de máquina.

* <b>Gradiente Descendiente</b><br>
  Método básico para minimizar funciones de manera iterativa utilizando el gradiente.<br>
  <i>Colaboradores: Wei Le Hu Tang, Diego Velasco Cortez.</i><br>
  [Resumen] <a href="">[Colab]</a> [PDF]

* <b>Gradiente Descendiente Estocástico</b><br>
  Adaptación del Gradiente Descendiente utilizada en aprendizaje de máquina para entrenar modelos.<br>
  <i>Colaboradores: Wei Le Hu Tang, Diego Velasco Cortez.</i><br>
  [Resumen] <a href="">[Colab]</a> [PDF]

* <b>Modelos Lineales</b><br>
  Modelo de predicción sencillo que puede entrenarse de forma cerrada o iterativa.<br>
  <i>Colaboradores: Jorge Aureo Armas Cuellar.</i><br>
  [Resumen] <a href="">[Colab]</a> [PDF]



## Colaboradores

* <i>Jorge Aureo Armas Cuellar</i><br>Licenciatura en Matemáticas Aplicadas, FC-UNAM

* <i>Alejandro Antonio Estrada Franco</i><br>Maestría en Matemáticas, IIMAS-UNAM

* <i>Alejandra Guerrero Arelio</i><br>Licenciatura en Matemáticas, FC-UNAM

* <i>Wei Le Hu Tang</i><br>Licenciatura en Matemáticas Aplicadas, FC-UNAM

* <i>Diego Velasco Cortez</i><br>Licenciatura en Actuaría, FC-UNAM

<br>

<b>INFORMACIÓN DE CONTACTO</b><br>
<i>Mario Diaz, IIMAS-UNAM</i><br>
<a href="https://www.mariodiaztorres.com/">https://www.mariodiaztorres.com/</a><br>
<a href="mailto:mario.diaz@sigma.iimas.unam.mx">mario.diaz@sigma.iimas.unam.mx</a><br>
